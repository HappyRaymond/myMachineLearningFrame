{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets  # 导入库\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston = datasets.load_boston()  # 导入波士顿房价数据\n",
    "\n",
    "train = boston.data  # sample\n",
    "target = boston.target  # target\n",
    "# 切割数据样本集合测试集\n",
    "X_train, x_test, y_train, y_true = train_test_split(train, target, test_size=0.2)  # 20%测试集；80%训练集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_Double.shape: (404, 2, 26) X_test_Double.shape: (102, 2, 26)\n"
     ]
    }
   ],
   "source": [
    "# 對特征做一個操作 讓它翻倍以免出現不是雙數的情況\n",
    "X_train_Double = []\n",
    "for line in X_train:\n",
    "    tempList = []\n",
    "    for l in line:\n",
    "        tempList.extend([l,l])\n",
    "    X_train_Double.append([np.array(tempList),np.array(tempList)])\n",
    "\n",
    "X_train_Double = np.array(X_train_Double)\n",
    "\n",
    "X_test_Double = []\n",
    "for line in x_test:\n",
    "    tempList = []\n",
    "    for l in line:\n",
    "        tempList.extend([l,l])\n",
    "    X_test_Double.append([np.array(tempList),np.array(tempList)])\n",
    "\n",
    "X_test_Double = np.array(X_test_Double)\n",
    "\n",
    "\n",
    "\n",
    "print(\"X_train_Double.shape:\",X_train_Double.shape,\"X_test_Double.shape:\",X_test_Double.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        \n",
    "        super(PositionalEncoding, self).__init__()      \n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        #pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(\"PositionalEncoding\",x.size())\n",
    "        \n",
    "        \n",
    "        return x + self.pe[:x.size(0), :]\n",
    "          \n",
    "\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self,feature_size=250,num_layers=1,dropout=0.1):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=2, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        self.decoder = nn.Linear(2*feature_size,1)\n",
    "        self.init_weights()\n",
    "        \n",
    "        self.feature_size = feature_size\n",
    "        self.num_layers   = num_layers\n",
    "        self.dropout      = dropout\n",
    "        \n",
    "    def feature(self):\n",
    "        return{\"feature_size\":self.feature_size,\"num_layers\":self.num_layers,\"dropout\":self.dropout}\n",
    "        \n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self,src):\n",
    "#         print(\"0\",src.shape)\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "#         print(\"1\",src.shape)\n",
    "        src = self.pos_encoder(src)\n",
    "#         print(\"2\",src.shape)\n",
    "        output = self.transformer_encoder(src,self.src_mask)#, self.src_mask)\n",
    "        output = output.view(output.shape[0], -1)\n",
    "#         print(\"3\",output.shape)\n",
    "        output = self.decoder(output)\n",
    "#         print(\"4\",output.shape)\n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择你要用的 GPU OR CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransAm(feature_size=26,num_layers=1,dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 433] 指定的裝置不存在。: 'transformer_Result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-4ed2ee71a6a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGeneral_Regression_Training_3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_more_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'transformer_Result'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-155-a9a124d7511f>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, net, learning_rate, batch_size, epoch, use_more_gpu, weight_decay, device, save_path)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_path\u001b[0m  \u001b[1;31m# 设置一条保存路径，直接把所有的值都收藏起来\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgLossList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# put the avgLoss data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 433] 指定的裝置不存在。: 'transformer_Result'"
     ]
    }
   ],
   "source": [
    "grt = General_Regression_Training_3d(model,learning_rate = [1e-3,1e-6,1e-8],batch_size = 512,use_more_gpu = False,weight_decay=1e-3, device = 0 ,save_path='transformer_Result',epoch = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-10976d76877a>:195: DeprecationWarning: 'U' mode is deprecated\n",
      "  count = len(open(save_result, 'rU').readlines())\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 433] 指定的裝置不存在。: 'transformer_Result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-ddfb078cdf2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_Double\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_Double\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-57-10976d76877a>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mnet_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Weight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mnet_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m             \u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m             \u001b[1;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 433] 指定的裝置不存在。: 'transformer_Result'"
     ]
    }
   ],
   "source": [
    "grt.fit(X_train_Double, y_train, X_test_Double, y_true )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "# standard library\n",
    "import os\n",
    "# third-party library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class General_Regression_Training_3d():\n",
    "\n",
    "    # 給優化函數判斷模型效果用的\n",
    "    def fitness(evaluationStr=\"r2\"):\n",
    "        if (evaluationStr == \"r2\"):\n",
    "            return self.r2\n",
    "        elif (evaluationStr == \"r2_adjusted\"):\n",
    "            return self.r2_adjusted\n",
    "        elif (evaluationStr == \"rmsle\"):\n",
    "            return self.rmsle\n",
    "        elif (evaluationStr == \"mape\"):\n",
    "            return self.mape\n",
    "        elif (evaluationStr == \"r2_adjusted\"):\n",
    "            return self.r2_adjusted\n",
    "        elif (evaluationStr == \"mad\"):\n",
    "            return self.mad\n",
    "        elif (evaluationStr == \"mae\"):\n",
    "            return self.mae\n",
    "    # 保存参数  预测值 真实值 图片\n",
    "    def save_results(self):\n",
    "        # , resultTitle, resultList, y_test, test_prediction, save_path\n",
    "        resultTitle     = [str(line) for line in self.resultDict.keys()]\n",
    "        resultList      = [ \"_\".join([ str(l) for l in line]) if isinstance(line,list) else str(line) for line in self.resultDict.values()]\n",
    "        y_test          = self.y_test\n",
    "        test_prediction = self.test_prediction\n",
    "        save_path       = self.save_path\n",
    "\n",
    "        # 计算行数，匹配 prediciton 的保存\n",
    "        save_result = \"/\".join([save_path, 'result.csv'])\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        try:\n",
    "            count = len(open(save_result, 'rU').readlines())\n",
    "        except:\n",
    "            count = 1\n",
    "\n",
    "        # 判断是否存在未见 没有则写入文件 有则追加写入\n",
    "        resultTitle.insert(0, \"count\")\n",
    "        resultList.insert(0, str(count))\n",
    "        \n",
    "        if not os.path.exists(save_result):\n",
    "            with open(save_result, 'w') as f:\n",
    "                titleStr = \",\".join(resultTitle)\n",
    "                f.write(titleStr)\n",
    "                f.write('\\n')\n",
    "        \n",
    "        with open(save_result, 'a+') as f:\n",
    "            contentStr = \",\".join(resultList)\n",
    "            f.write(contentStr)\n",
    "            f.write('\\n')\n",
    "        # 保存 train loss 和 test loss\n",
    "        Loss_path = os.path.join(save_path, 'Loss')\n",
    "        if not os.path.exists(Loss_path):\n",
    "            os.makedirs(Loss_path)\n",
    "        \n",
    "        save_Loss = os.path.join(Loss_path, str(count) + '.csv')\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        df[\"TrainLoss\"] = self.TrainLosses\n",
    "        df[\"TestLoss\"] = self.TestLosses\n",
    "        df.to_csv(save_Loss, index=False)\n",
    "        # 保存 prediction\n",
    "        pred_path = os.path.join(save_path, 'Prediction')\n",
    "        if not os.path.exists(pred_path):\n",
    "            os.makedirs(pred_path)\n",
    "\n",
    "        save_prediction = os.path.join(pred_path, str(count) + '.csv')\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        df[\"y_test\"] = [i for i in y_test]\n",
    "        df[\"test_prediction\"] =[i for i in test_prediction]\n",
    "        df.to_csv(save_prediction, index=False)\n",
    "\n",
    "        print('Save the value of prediction successfully!!')\n",
    "\n",
    "        # save the model weight\n",
    "        model_path = os.path.join(save_path, 'Model')\n",
    "        if not os.path.exists(model_path):\n",
    "            os.makedirs(model_path)\n",
    "\n",
    "        if(self.use_more_gpu):\n",
    "            torch.save(self.net.state_dict(), os.path.join(model_path, str(count) + \".pth\"))\n",
    "        else:\n",
    "            torch.save(self.net.state_dict(), os.path.join(model_path, str(count) + \".pth\"))\n",
    "\n",
    "        return count\n",
    "\n",
    "\n",
    "    def reg_calculate(self,true, prediction, features=None):\n",
    "        '''\n",
    "            To calculate the result of regression,\n",
    "            including mse, rmse, mae, r2, four criterions.\n",
    "        '''\n",
    "        prediction[prediction < 0] = 0\n",
    "\n",
    "        mse = metrics.mean_squared_error(true, prediction)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        mae = metrics.mean_absolute_error(true, prediction)\n",
    "        mape = np.mean(np.abs((true - prediction) / true)) * 100\n",
    "\n",
    "        r2 = metrics.r2_score(true, prediction)\n",
    "        rmsle = np.sqrt(metrics.mean_squared_log_error(true, prediction))\n",
    "\n",
    "        try:\n",
    "            n = len(true)\n",
    "            p = features\n",
    "            r2_adjusted = 1-((1-metrics.r2_score(true, prediction))*(n-1))/(n-p-1)\n",
    "        except:\n",
    "            # print(\"mse: {}, rmse: {}, mae: {}, mape: {}, r2: {}, rmsle: {}\".format(mse, rmse, mae, mape, r2, rmsle))\n",
    "            print('if you wanna get the value of r2_adjusted, you can define the number of features, '\n",
    "                  'which is the third parameter.')\n",
    "            return mse, rmse, mae, mape, r2, rmsle\n",
    "\n",
    "        # print(\"mse: {}, rmse: {}, mae: {}, mape: {}, r2: {}, r2_adjusted: {}, rmsle: {}\".format(mse, rmse, mae, mape,r2, r2_adjusted, rmsle))\n",
    "        return mse, rmse, mae, mape, r2, r2_adjusted, rmsle\n",
    "\n",
    "\n",
    "    def __init__(self,net,learning_rate = [1e-3,1e-5,1e-7], batch_size = 1024, epoch = 2000, use_more_gpu = False,weight_decay=1e-8, device=0 ,save_path='CNN_Result'):\n",
    "\n",
    "        self.net = net\n",
    "        self.resultDict = {\"learning_rate\":learning_rate,\"batch_size\":batch_size,\"epoch\":epoch,\"weight_decay\":weight_decay,\"use_more_gpu\":use_more_gpu,\"device\":device,}\n",
    "        self.resultDict = dict(self.resultDict,**self.net.feature())\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.use_more_gpu = use_more_gpu\n",
    "        self.lr = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.weight_decay = weight_decay\n",
    "        self.device = device\n",
    "        self.epoch = epoch\n",
    "        \n",
    "        self.save_path = save_path  # 设置一条保存路径，直接把所有的值都收藏起来\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "\n",
    "        self.avgLossList = []  # put the avgLoss data\n",
    "        self.TrainLosses = []\n",
    "        self.TestLosses = []\n",
    "        self.t = 0\n",
    "        self.D = []\n",
    "        self.n = 0  # 来记录 梯度衰减 的次数\n",
    "        self.limit = [1e-5, 1e-6, 1e-7]\n",
    "        \n",
    "    # 創建數據生成器\n",
    "    def create_batch_size(self, X_train, y_train):\n",
    "        p = np.random.permutation(X_train.shape[0])\n",
    "        data = X_train[p]\n",
    "        label = y_train[p]\n",
    "\n",
    "        batch_size = self.batch_size\n",
    "        batch_len = X_train.shape[0] // batch_size + 1\n",
    "\n",
    "        b_datas = []\n",
    "        b_labels = []\n",
    "        for i in range(batch_len):\n",
    "            try:\n",
    "                batch_data = data[batch_size * i: batch_size * (i + 1)]\n",
    "                batch_label = label[batch_size * i: batch_size * (i + 1)]\n",
    "            except:\n",
    "                batch_data = data[batch_size * i: -1]\n",
    "                batch_label = label[batch_size * i: -1]\n",
    "            b_datas.append(batch_data)\n",
    "            b_labels.append(batch_label)\n",
    "\n",
    "        return b_datas, b_labels\n",
    "    \n",
    "    \n",
    "        \n",
    "    # 訓練函數\n",
    "    def fit(self, X_train, y_train, X_test, y_test):\n",
    "        ''' training the network '''\n",
    "        # input the dataset and transform into dataLoad\n",
    "        # if y is a scalar\n",
    "        if y_train.ndim == 1:\n",
    "            y_train = y_train.reshape(-1, 1)\n",
    "        \n",
    "        if y_test.ndim == 1:\n",
    "            y_test = y_test.reshape(-1, 1)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "        \n",
    "\n",
    "        b_data, b_labels = self.create_batch_size(X_train, y_train)\n",
    "        \n",
    "        save_result = os.path.join(self.save_path, 'Results.csv')\n",
    "        try:\n",
    "            count = len(open(save_result, 'rU').readlines())\n",
    "        except:\n",
    "            count = 1\n",
    "\n",
    "        net_weight = os.path.join(self.save_path, 'Weight')\n",
    "        if not os.path.exists(net_weight):\n",
    "            os.makedirs(net_weight)\n",
    "        \n",
    "        net_path = os.path.join(net_weight, str(count) + '.pkl')\n",
    "        net_para_path = os.path.join(net_weight, str(count) + '_parameters.pkl')\n",
    "        \n",
    "        \n",
    "    \n",
    "        # set the net use cpu or gpu\n",
    "        device = torch.device(self.device if torch.cuda.is_available() else \"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"Let's use GPU: {}\".format(self.device))\n",
    "        else:\n",
    "            print(\"Let's use CPU\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        if self.use_more_gpu and torch.cuda.device_count() > 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs\")\n",
    "            # dim = 0 [64, xxx] -> [32, ...], [32, ...] on 2GPUs\n",
    "            self.net = nn.DataParallel(self.net)\n",
    "        self.net.to(device)\n",
    "        \n",
    "        # network change to train model \n",
    "        self.net.train()\n",
    "        # set optimizer and loss function\n",
    "        try:\n",
    "            optim = torch.optim.Adam(self.net.parameters(), lr=self.lr[0], weight_decay=self.weight_decay)\n",
    "        except:\n",
    "            optim = torch.optim.Adam(self.net.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        print(\"\")\n",
    "        # Officially start training\n",
    "\n",
    "        start = time.time() # 计算时间\n",
    "        limit = self.limit[0]\n",
    "        for e in range(self.epoch):\n",
    "            \n",
    "            tempLoss = []\n",
    "            # 訓練模式\n",
    "            self.net.train()\n",
    "            for i in range(len(b_data)):\n",
    "                if torch.cuda.is_available():\n",
    "                    #print('cuda')\n",
    "                    #self.net = self.net.cuda()\n",
    "                    train_x = Variable(torch.FloatTensor(b_data[i])).to(device)\n",
    "                    train_y = Variable(torch.FloatTensor(b_labels[i])).to(device)\n",
    "                else:\n",
    "                    train_x = Variable(torch.FloatTensor(b_data[i]))\n",
    "                    train_y = Variable(torch.FloatTensor(b_labels[i]))\n",
    "\n",
    "\n",
    "                prediction = self.net(train_x)\n",
    "                \n",
    "                loss = criterion(prediction, train_y)\n",
    "                tempLoss.append(float(loss))\n",
    "                \n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "            self.D.append(loss.cpu().data.numpy())\n",
    "            avgloss =  np.array(tempLoss).sum() / len(tempLoss)\n",
    "            self.avgLossList.append(avgloss)\n",
    "            \n",
    "            \n",
    "            if( ( e + 1 ) % 100 == 0):\n",
    "                print('Training... epoch: {}, loss: {}'.format((e + 1), self.avgLossList[-1]))\n",
    "\n",
    "                self.net.eval()\n",
    "                if torch.cuda.is_available():\n",
    "                    test_x = Variable(torch.FloatTensor(self.X_test)).to(device)\n",
    "                    test_y = Variable(torch.FloatTensor(self.y_test)).to(device)\n",
    "                else:\n",
    "                    test_x = Variable(torch.FloatTensor(self.X_test))\n",
    "                    test_y = Variable(torch.FloatTensor(self.y_test))\n",
    "\n",
    "                test_prediction = self.net(test_x)\n",
    "                test_loss = criterion(test_prediction, test_y)\n",
    "\n",
    "                self.TrainLosses.append(avgloss)\n",
    "                self.TestLosses.append(test_loss.cpu().data.numpy())\n",
    "\n",
    "                self.test_prediction = test_prediction.cpu().data.numpy()\n",
    "                self.test_prediction[self.test_prediction < 0] = 0\n",
    "                # self.mse, self.rmse, self.mae, self.mape, \\\n",
    "                #     self.r2, self.r2_adjusted, self.rmsle = self.reg_calculate(self.y_test, self.test_prediction  ,self.X_test.shape[-1] )\n",
    "\n",
    "\n",
    "                #test_acc = self.__get_acc(test_prediction, test_y)\n",
    "                # print('\\033[1;35m Testing... epoch: {}, loss: {} , r2 {}\\033[0m!'.format((e + 1), test_loss.cpu().data.numpy(), self.r2))\n",
    "\n",
    "                \n",
    "                \n",
    "#                 plt.figure(figsize = (7,5))       #figsize是图片的大小`\n",
    "#                 plt.plot( [i for  i in range(len(self.avgLossList))] ,self.avgLossList,'g-',label=u'Dense_Unet(block layer=5)')\n",
    "#                 plt.legend()\n",
    "#                 plt.xlabel(u'iters')\n",
    "#                 plt.ylabel(u'loss')\n",
    "#                 plt.title('Compare loss for different models in training')\n",
    "#                 plt.show()\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            # epoch 终止装置\n",
    "            if len(self.D) >= 20:\n",
    "                loss1 = np.mean(np.array(self.D[-20:-10]))\n",
    "                loss2 = np.mean(np.array(self.D[-10:]))\n",
    "                d = np.float(np.abs(loss2 - loss1)) # 計算loss的差值\n",
    "\n",
    "                \n",
    "                if d < limit or e == self.epoch-1  or e > (self.epoch-1)/3 * (self.n + 1)   : # 加入遍历完都没达成limit限定，就直接得到结果  \n",
    "                    \n",
    "                    self.D = []  # 重置\n",
    "                    self.n += 1\n",
    "                    print('The error changes within {}'.format(limit))\n",
    "                    self.e = e + 1\n",
    "\n",
    "\n",
    "                    #train_acc = self.__get_acc(prediction, train_y)\n",
    "                    print(\n",
    "                        'Training... epoch: {}, loss: {}'.format((e + 1), loss.cpu().data.numpy()))\n",
    "                    \n",
    "                    # torch.save(self.net.module.state_dict(), model_out_path) 多 GPU 保存\n",
    "                    \n",
    "                    torch.save(self.net, net_path)\n",
    "                    torch.save(self.net.state_dict(), net_para_path)\n",
    "                    \n",
    "                    self.net.eval()\n",
    "                    if torch.cuda.is_available():\n",
    "                        test_x = Variable(torch.FloatTensor(self.X_test)).to(device)\n",
    "                        test_y = Variable(torch.FloatTensor(self.y_test)).to(device)\n",
    "                    else:\n",
    "                        test_x = Variable(torch.FloatTensor(self.X_test))\n",
    "                        test_y = Variable(torch.FloatTensor(self.y_test))\n",
    "                    \n",
    "                    test_prediction = self.net(test_x)\n",
    "                    test_loss = criterion(test_prediction, test_y)\n",
    "\n",
    "                \n",
    "                    self.test_prediction = test_prediction.cpu().data.numpy()\n",
    "                    self.test_prediction[self.test_prediction < 0] = 0\n",
    "                    \n",
    "#                     print(\"self.y_test\",np.array(self.y_test).shape)\n",
    "#                     print(\"self.test_prediction\",self.test_prediction.shape)\n",
    "#                     print(\"self.test_prediction\",self.test_prediction)\n",
    "#                     print(\"self.X_test.shape[-1]\",self.X_test.shape[-1])\n",
    "                    \n",
    "                    self.mse, self.rmse, self.mae, self.mape, \\\n",
    "                        self.r2, self.r2_adjusted, self.rmsle = self.reg_calculate(self.y_test, self.test_prediction  ,self.X_test.shape[-1] )\n",
    "                        \n",
    "                    \n",
    "                    #test_acc = self.__get_acc(test_prediction, test_y)\n",
    "                    print('\\033[1;35m Testing... epoch: {}, loss: {} , r2 {}\\033[0m!'.format((e + 1), test_loss.cpu().data.numpy(), self.r2))\n",
    "                    \n",
    "                    # 已经梯度衰减了 2 次\n",
    "                    if self.n == 3:\n",
    "                        print('The meaning of the loop is not big, stop!!')\n",
    "                        break\n",
    "                    limit = self.limit[self.n]\n",
    "                    print('Now learning rate is : {}'.format(self.lr[self.n]))\n",
    "                    optim.param_groups[0][\"lr\"] = self.lr[self.n]\n",
    "            \n",
    "            \n",
    "        end = time.time()\n",
    "        self.t = end - start\n",
    "        print('Training completed!!! Time consuming: {}'.format(str(self.t)))\n",
    "\n",
    "        #\n",
    "        resDict = {\"mse\":self.mse, \"rmse\":self.rmse, \"mae\":self.mae, \"mape\":self.mape, \"r2\":self.r2, \"r2_adjusted\":self.r2_adjusted, \"rmsle\":self.rmsle}\n",
    "        self.resultDict = dict(resDict,**self.resultDict)\n",
    "\n",
    "        # 计算结果\n",
    "        self.mse, self.rmse, self.mae, self.mape, \\\n",
    "        self.r2, self.r2_adjusted, self.rmsle = self.reg_calculate(self.y_test, self.test_prediction,\n",
    "                                                                    self.X_test.shape[-1])\n",
    "        \n",
    "    \n",
    "        \n",
    "        # 給優化函數判斷模型效果用的 \n",
    "    def fitness(evaluationStr = \"r2\"):\n",
    "        if(evaluationStr == \"r2\"):\n",
    "            return self.r2\n",
    "        elif(evaluationStr == \"r2_adjusted\"):\n",
    "            return  self.r2_adjusted\n",
    "        elif(evaluationStr == \"rmsle\"):\n",
    "            return  self.rmsle\n",
    "        elif(evaluationStr == \"mape\"):\n",
    "            return  self.mape\n",
    "        elif(evaluationStr == \"r2_adjusted\"):\n",
    "            return  self.r2_adjusted\n",
    "        elif(evaluationStr == \"mad\"):\n",
    "            return  self.mad\n",
    "        elif(evaluationStr == \"mae\"):\n",
    "            return  self.mae\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if window is 100 and prediction step is 1\n",
    "# in -> [0..99]\n",
    "# target -> [1..100]\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+output_window:i+tw+output_window]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return torch.FloatTensor(inout_seq)\n",
    "\n",
    "def get_data():\n",
    "    # construct a littel toy dataset\n",
    "    time        = np.arange(0, 400, 0.1)    \n",
    "    amplitude   = np.sin(time) + np.sin(time*0.05) +np.sin(time*0.12) *np.random.normal(-0.2, 0.2, len(time))\n",
    "\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    #loading weather data from a file\n",
    "    #from pandas import read_csv\n",
    "    #series = read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "    \n",
    "    # looks like normalizing input values curtial for the model\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1)) \n",
    "    #amplitude = scaler.fit_transform(series.to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "    amplitude = scaler.fit_transform(amplitude.reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "    \n",
    "    sampels = 2600\n",
    "    train_data = amplitude[:sampels]\n",
    "    test_data = amplitude[sampels:]\n",
    "\n",
    "    # convert our train data into a pytorch train tensor\n",
    "    #train_tensor = torch.FloatTensor(train_data).view(-1)\n",
    "    # todo: add comment.. \n",
    "    train_sequence = create_inout_sequences(train_data,input_window)\n",
    "    train_sequence = train_sequence[:-output_window] #todo: fix hack? -> din't think this through, looks like the last n sequences are to short, so I just remove them. Hackety Hack.. \n",
    "    \n",
    "    #test_data = torch.FloatTensor(test_data).view(-1) \n",
    "    test_data = create_inout_sequences(test_data,input_window)\n",
    "    test_data = test_data[:-output_window] #todo: fix hack?\n",
    "\n",
    "    return train_sequence.to(device),test_data.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
