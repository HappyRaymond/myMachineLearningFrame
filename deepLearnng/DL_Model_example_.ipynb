{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入波士顿房价数据作为示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets  # 导入库\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "boston = datasets.load_boston()  # 导入波士顿房价数据\n",
    "\n",
    "train = boston.data  # sample\n",
    "target = boston.target  # target\n",
    "# 切割数据样本集合测试集\n",
    "X_train, x_test, y_train, y_true = train_test_split(train, target, test_size=0.2)  # 20%测试集；80%训练集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_Double.shape: (404, 2, 26) X_test_Double.shape: (102, 2, 26)\n"
     ]
    }
   ],
   "source": [
    "# 對特征做一個操作 讓它翻倍以免出現不是雙數的情況\n",
    "X_train_Double = []\n",
    "for line in X_train:\n",
    "    tempList = []\n",
    "    for l in line:\n",
    "        tempList.extend([l,l])\n",
    "    X_train_Double.append([np.array(tempList),np.array(tempList)])\n",
    "\n",
    "X_train_Double = np.array(X_train_Double)\n",
    "\n",
    "X_test_Double = []\n",
    "for line in x_test:\n",
    "    tempList = []\n",
    "    for l in line:\n",
    "        tempList.extend([l,l])\n",
    "    X_test_Double.append([np.array(tempList),np.array(tempList)])\n",
    "\n",
    "X_test_Double = np.array(X_test_Double)\n",
    "\n",
    "\n",
    "\n",
    "print(\"X_train_Double.shape:\",X_train_Double.shape,\"X_test_Double.shape:\",X_test_Double.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Frame.DeepLearningModel import CNN1D,TransAm,TransAm_CNN_1D,TransAm_CNN_LSTM,TransAm_LSTM\n",
    "from Frame.DeepLearningRegression import General_Regression_Training_3d,General_Regression_Training\n",
    "\n",
    "ROOT_SAVE_PATH = \"./DeepLeaning/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "####  TransAm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransAm(feature_size=26,\n",
    "                num_layers=2,\n",
    "                dropout=0.5,\n",
    "                stackNum = 2,\n",
    "                activate_function = 'LeakyReLU',\n",
    "                hidden_layers = [1024,512])\n",
    "\n",
    "grt = General_Regression_Training_3d(model,learning_rate = [1e-3,1e-6,1e-8],\n",
    "                                     batch_size = 512,\n",
    "                                     use_more_gpu = False,\n",
    "                                     weight_decay=1e-3, \n",
    "                                     device=0,\n",
    "                                     save_path=ROOT_SAVE_PATH + 'transformer_Result',\n",
    "                                     epoch = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use CPU\n",
      "\n",
      "The error changes within 1e-05\n",
      "Training... epoch: 68, loss: 62.85170364379883\n",
      "\u001b[1;35m Testing... epoch: 68, loss: 105.0954360961914 , r2 -0.1328201267781568\u001b[0m!\n",
      "Now learning rate is : 1e-06\n",
      "Training... epoch: 100, loss: 63.19963455200195\n",
      "The error changes within 1e-06\n",
      "Training... epoch: 134, loss: 65.38162231445312\n",
      "\u001b[1;35m Testing... epoch: 134, loss: 105.3754653930664 , r2 -0.13583861631870064\u001b[0m!\n",
      "Now learning rate is : 1e-08\n",
      "Training... epoch: 200, loss: 63.61469650268555\n",
      "The error changes within 1e-07\n",
      "Training... epoch: 200, loss: 63.61469650268555\n",
      "\u001b[1;35m Testing... epoch: 200, loss: 105.37838745117188 , r2 -0.13587014782501594\u001b[0m!\n",
      "The meaning of the loop is not big, stop!!\n",
      "Training completed!!! Time consuming: 10.879013776779175\n"
     ]
    }
   ],
   "source": [
    "grt.fit(X_train_Double, y_train, X_test_Double, y_true )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransAm_CNN_1D(feature_size=26, \n",
    "                        num_layers=1, \n",
    "                        dropout=0.1,\n",
    "                        stackNum = 2,\n",
    "                        activate_function = 'LeakyReLU',\n",
    "                        channel_layers = [32,18],\n",
    "                        kernel_size = 3,\n",
    "                        stride = 1,\n",
    "                        padding=1,\n",
    "                        Pool_kernel_size = 1,\n",
    "                        dim_feedforward_num=2048,\n",
    "                        nhead=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grt = General_Regression_Training_3d(model,learning_rate = [1e-3,1e-6,1e-8],\n",
    "                                     batch_size = 512,\n",
    "                                     use_more_gpu = False,\n",
    "                                     weight_decay=1e-3, \n",
    "                                     device=0 ,\n",
    "                                     save_path=ROOT_SAVE_PATH + 'transformer_Cnn1d_Result',\n",
    "                                     epoch = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use CPU\n",
      "\n",
      "The error changes within 1e-05\n",
      "Training... epoch: 68, loss: 61.33563232421875\n",
      "\u001b[1;35m Testing... epoch: 68, loss: 68.91443634033203 , r2 0.29577096392513846\u001b[0m!\n",
      "Now learning rate is : 1e-06\n",
      "Training... epoch: 100, loss: 59.8307991027832\n",
      "The error changes within 1e-06\n",
      "Training... epoch: 134, loss: 59.5714225769043\n",
      "\u001b[1;35m Testing... epoch: 134, loss: 68.49394226074219 , r2 0.3000679566265837\u001b[0m!\n",
      "Now learning rate is : 1e-08\n",
      "Training... epoch: 200, loss: 59.63883972167969\n",
      "The error changes within 1e-07\n",
      "Training... epoch: 200, loss: 59.63883972167969\n",
      "\u001b[1;35m Testing... epoch: 200, loss: 68.49417114257812 , r2 0.30006556428655107\u001b[0m!\n",
      "The meaning of the loop is not big, stop!!\n",
      "Training completed!!! Time consuming: 8.57247018814087\n"
     ]
    }
   ],
   "source": [
    "grt.fit(X_train_Double, y_train, X_test_Double, y_true )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransAm_LSTM(feature_size=26,\n",
    "                        num_layers=1,\n",
    "                        dropout=0.1,\n",
    "                        stackNum=2, \n",
    "                        activate_function='LeakyReLU',\n",
    "                        nhead=2,\n",
    "                        dim_feedforward_num = 2048,\n",
    "#                         channel_layers=[32, 18],\n",
    "#                         kernel_size=3, \n",
    "#                         stride=1, \n",
    "#                         padding=1,\n",
    "#                         Pool_kernel_size=1,\n",
    "                        LSTM_hidden_size=32, \n",
    "                        LSTM_num_layers=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grt = General_Regression_Training_3d(model,learning_rate = [1e-3,1e-6,1e-8],\n",
    "                                     batch_size = 512,\n",
    "                                     use_more_gpu = False,\n",
    "                                     weight_decay=1e-3, \n",
    "                                     device=0 ,\n",
    "                                     save_path=ROOT_SAVE_PATH + 'transformer_Cnn1d_Result',\n",
    "                                     epoch = 2000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use CPU\n",
      "\n",
      "Training... epoch: 100, loss: 59.39693832397461\n",
      "Training... epoch: 200, loss: 50.03814697265625\n",
      "Training... epoch: 300, loss: 40.51647186279297\n",
      "Training... epoch: 400, loss: 23.737686157226562\n",
      "Training... epoch: 500, loss: 29.4011173248291\n",
      "Training... epoch: 600, loss: 19.85297966003418\n",
      "The error changes within 1e-05\n",
      "Training... epoch: 668, loss: 20.001575469970703\n",
      "\u001b[1;35m Testing... epoch: 668, loss: 54.016868591308594 , r2 0.39875327989466547\u001b[0m!\n",
      "Now learning rate is : 1e-06\n",
      "Training... epoch: 700, loss: 17.63358497619629\n",
      "Training... epoch: 800, loss: 19.510828018188477\n",
      "Training... epoch: 900, loss: 19.181936264038086\n",
      "Training... epoch: 1000, loss: 17.615489959716797\n",
      "Training... epoch: 1100, loss: 18.654415130615234\n",
      "Training... epoch: 1200, loss: 20.350872039794922\n",
      "Training... epoch: 1300, loss: 18.70170783996582\n",
      "The error changes within 1e-06\n",
      "Training... epoch: 1334, loss: 20.26751136779785\n",
      "\u001b[1;35m Testing... epoch: 1334, loss: 50.69327926635742 , r2 0.4357472268953553\u001b[0m!\n",
      "Now learning rate is : 1e-08\n",
      "Training... epoch: 1400, loss: 19.56740379333496\n",
      "Training... epoch: 1500, loss: 21.602636337280273\n",
      "Training... epoch: 1600, loss: 17.94367027282715\n",
      "Training... epoch: 1700, loss: 16.18454933166504\n",
      "Training... epoch: 1800, loss: 17.768177032470703\n",
      "Training... epoch: 1900, loss: 20.926982879638672\n",
      "Training... epoch: 2000, loss: 20.785137176513672\n",
      "The error changes within 1e-07\n",
      "Training... epoch: 2000, loss: 20.785137176513672\n",
      "\u001b[1;35m Testing... epoch: 2000, loss: 50.679988861083984 , r2 0.435895125966132\u001b[0m!\n",
      "The meaning of the loop is not big, stop!!\n",
      "Training completed!!! Time consuming: 53.412400007247925\n"
     ]
    }
   ],
   "source": [
    "grt.fit(X_train_Double, y_train, X_test_Double, y_true )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the value of prediction successfully!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grt.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransAm_CNN_LSTM(feature_size=26,\n",
    "                        num_layers=1,\n",
    "                        dropout=0.1,\n",
    "                        stackNum=2, \n",
    "                        activate_function='LeakyReLU',\n",
    "                        nhead=2,\n",
    "                        dim_feedforward_num = 2048,\n",
    "                        channel_layers=[32, 18],\n",
    "                        kernel_size=3, \n",
    "                        stride=1, \n",
    "                        padding=1,\n",
    "                        Pool_kernel_size=1,\n",
    "                        LSTM_hidden_size=32, \n",
    "                        LSTM_num_layers=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grt = General_Regression_Training_3d(model,learning_rate = [1e-3,1e-6,1e-8],\n",
    "                                     batch_size = 512,\n",
    "                                     use_more_gpu = False,\n",
    "                                     weight_decay=1e-3, \n",
    "                                     device=0 ,\n",
    "                                     save_path=ROOT_SAVE_PATH +'transformer_Cnn1d_Result',\n",
    "                                     epoch = 2000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use CPU\n",
      "\n",
      "Training... epoch: 100, loss: 32.1661376953125\n",
      "Training... epoch: 200, loss: 19.446380615234375\n",
      "Training... epoch: 300, loss: 18.86509895324707\n",
      "Training... epoch: 400, loss: 19.747257232666016\n",
      "Training... epoch: 500, loss: 21.110525131225586\n",
      "Training... epoch: 600, loss: 13.567580223083496\n",
      "The error changes within 1e-05\n",
      "Training... epoch: 668, loss: 14.739835739135742\n",
      "\u001b[1;35m Testing... epoch: 668, loss: 54.694679260253906 , r2 0.3912087610434011\u001b[0m!\n",
      "Now learning rate is : 1e-06\n",
      "Training... epoch: 700, loss: 15.805787086486816\n",
      "Training... epoch: 800, loss: 13.213703155517578\n",
      "Training... epoch: 900, loss: 13.2622652053833\n",
      "Training... epoch: 1000, loss: 14.362970352172852\n",
      "Training... epoch: 1100, loss: 12.916044235229492\n",
      "Training... epoch: 1200, loss: 11.873624801635742\n",
      "Training... epoch: 1300, loss: 12.261518478393555\n",
      "The error changes within 1e-06\n",
      "Training... epoch: 1334, loss: 13.569530487060547\n",
      "\u001b[1;35m Testing... epoch: 1334, loss: 53.438331604003906 , r2 0.40519273698289326\u001b[0m!\n",
      "Now learning rate is : 1e-08\n",
      "Training... epoch: 1400, loss: 14.847965240478516\n",
      "Training... epoch: 1500, loss: 14.19314193725586\n",
      "Training... epoch: 1600, loss: 13.45776081085205\n",
      "Training... epoch: 1700, loss: 14.80615520477295\n",
      "Training... epoch: 1800, loss: 13.385847091674805\n",
      "Training... epoch: 1900, loss: 12.038202285766602\n",
      "Training... epoch: 2000, loss: 13.180410385131836\n",
      "The error changes within 1e-07\n",
      "Training... epoch: 2000, loss: 13.180410385131836\n",
      "\u001b[1;35m Testing... epoch: 2000, loss: 53.440185546875 , r2 0.4051721728018459\u001b[0m!\n",
      "The meaning of the loop is not big, stop!!\n",
      "Training completed!!! Time consuming: 54.17252492904663\n"
     ]
    }
   ],
   "source": [
    "grt.fit(X_train_Double, y_train, X_test_Double, y_true )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the value of prediction successfully!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grt.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
